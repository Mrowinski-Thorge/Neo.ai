<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>NeoAI • Private Local AI</title>
    
    <!-- Preconnect for performance -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>
    
    <!-- Stylesheets -->
    <link rel="stylesheet" href="css/main.css">

    <!-- Inline critical styles for smooth loading -->
    <style>
        /* Base */
        body {
            background-color: theme('colors.background');
            color: #d4d4d8;
            -webkit-font-smoothing: antialiased;
            overflow: hidden; /* App-Feeling */
        }

        /* Ambient Background Glow */
        .ambient-glow {
            position: fixed;
            top: -20%;
            left: -10%;
            width: 50vw;
            height: 50vw;
            background: radial-gradient(circle, rgba(59, 130, 246, 0.08) 0%, transparent 70%);
            border-radius: 50%;
            filter: blur(80px);
            z-index: -1;
            pointer-events: none;
        }
        .ambient-glow-2 {
            position: fixed;
            bottom: -20%;
            right: -10%;
            width: 60vw;
            height: 60vw;
            background: radial-gradient(circle, rgba(147, 51, 234, 0.06) 0%, transparent 70%);
            border-radius: 50%;
            filter: blur(100px);
            z-index: -1;
            pointer-events: none;
        }

        /* Glass Components */
        .glass-panel {
            background: theme('colors.glass');
            backdrop-filter: blur(24px);
            -webkit-backdrop-filter: blur(24px);
            border: 1px solid theme('colors.glass_border');
        }

        .glass-button {
            background: rgba(255, 255, 255, 0.04);
            border: 1px solid rgba(255, 255, 255, 0.05);
            transition: all 0.2s ease;
        }
        .glass-button:hover {
            background: rgba(255, 255, 255, 0.08);
            border-color: rgba(255, 255, 255, 0.1);
            transform: translateY(-1px);
        }
        .glass-button:active {
            transform: translateY(0);
        }

        /* Scrollbar minimalist */
        ::-webkit-scrollbar { width: 4px; }
        ::-webkit-scrollbar-track { background: transparent; }
        ::-webkit-scrollbar-thumb { background: #333; border-radius: 2px; }
        ::-webkit-scrollbar-thumb:hover { background: #555; }

        /* Dialog Animation */
        dialog { 
            animation: fadeOut 0.2s ease-out; 
            opacity: 0; 
            transform: scale(0.98); 
        }
        dialog[open] { 
            animation: fadeIn 0.3s cubic-bezier(0.16, 1, 0.3, 1) forwards;
        }
        dialog::backdrop {
            background: rgba(0,0,0,0.6);
            backdrop-filter: blur(4px);
            animation: fadeInBack 0.3s ease-out forwards;
        }
        
        @keyframes fadeIn { to { opacity: 1; transform: scale(1); } }
        @keyframes fadeOut { to { opacity: 0; transform: scale(0.98); } }
        @keyframes fadeInBack { from { opacity: 0; } to { opacity: 1; } }

        /* Markdown Prose Overrides */
        .prose { max-width: none; font-size: 0.95rem; line-height: 1.65; }
        .prose p { margin-bottom: 0.8em; }
        .prose pre {
            background: #121212 !important;
            border: 1px solid rgba(255,255,255,0.08);
            border-radius: 12px;
            margin: 1em 0;
        }
        .prose code {
            color: #a1a1aa;
            background: rgba(255,255,255,0.06);
            padding: 2px 5px;
            border-radius: 4px;
            font-weight: 400;
        }
        .prose pre code { background: transparent; padding: 0; color: inherit; }
        /* Links in Prose */
        .prose a { color: #60a5fa; text-decoration: none; border-bottom: 1px dashed rgba(96,165,250,0.4); }
        .prose a:hover { border-bottom-style: solid; }

        /* Cursor */
        .cursor-blink::after {
            content: '';
            display: inline-block;
            width: 2px;
            height: 1em;
            background: #60a5fa;
            margin-left: 2px;
            animation: blink 1s step-end infinite;
            vertical-align: text-bottom;
        }
        @keyframes blink { 50% { opacity: 0; } }

    </style>
</head>
<body class="h-screen flex text-gray-200">

    <div class="ambient-glow"></div>
    <div class="ambient-glow-2"></div>

    <!-- Sidebar (Desktop) -->
    <aside id="sidebar" class="hidden md:flex flex-col w-[260px] h-full glass-panel border-r border-r-white/5 z-20">
        <div class="p-5 flex items-center gap-3 border-b border-white/5">
            <div class="w-8 h-8 rounded-xl bg-gradient-to-br from-blue-500/20 to-purple-500/20 flex items-center justify-center border border-white/10">
                <i data-lucide="sparkles" class="w-4 h-4 text-blue-400"></i>
            </div>
            <span class="font-medium text-gray-100 tracking-tight">NeoAI</span>
        </div>

        <div class="flex-1 overflow-y-auto p-3 space-y-1" id="chat-list">
            <!-- Dynamisch -->
        </div>

        <div class="p-3 border-t border-white/5">
             <button id="new-chat-btn" class="w-full glass-button py-2.5 px-4 rounded-xl flex items-center justify-center gap-2 text-sm font-medium text-gray-300 hover:text-white mb-2">
                <i data-lucide="plus" class="w-4 h-4"></i>
                Neuer Chat
            </button>
            <button id="settings-trigger" class="w-full glass-button py-2.5 px-4 rounded-xl flex items-center justify-start gap-3 text-sm text-gray-400 hover:text-white">
                <i data-lucide="settings-2" class="w-4 h-4"></i>
                Einstellungen
            </button>
        </div>
    </aside>

    <!-- Mobile Header -->
    <header class="md:hidden fixed top-0 left-0 right-0 h-14 glass-panel z-50 flex items-center justify-between px-4 border-b border-white/5">
        <button id="mobile-menu-btn" class="p-2 text-gray-400 active:text-white"><i data-lucide="menu"></i></button>
        <div class="flex items-center gap-2">
             <i data-lucide="sparkles" class="w-4 h-4 text-blue-400"></i>
             <span class="font-medium">NeoAI</span>
        </div>
        <button id="mobile-new-chat" class="p-2 text-gray-400 active:text-white"><i data-lucide="plus"></i></button>
    </header>

    <!-- Mobile Sidebar Overlay -->
    <div id="mobile-overlay" class="fixed inset-0 bg-black/80 backdrop-blur-sm z-40 hidden md:hidden opacity-0 transition-opacity duration-300"></div>
    <aside id="mobile-sidebar" class="fixed inset-y-0 left-0 w-[280px] bg-[#09090b] z-50 transform -translate-x-full transition-transform duration-300 md:hidden flex flex-col border-r border-white/10">
        <!-- Content clone of desktop sidebar via JS or structure -->
        <div class="p-5 flex items-center justify-between border-b border-white/5">
            <span class="font-bold">Verlauf</span>
            <button id="close-mobile-nav" class="p-1"><i data-lucide="x" class="w-5 h-5"></i></button>
        </div>
        <div class="flex-1 overflow-y-auto p-3" id="mobile-chat-list"></div>
        <div class="p-4 border-t border-white/5">
            <button id="mobile-settings-btn" class="flex items-center gap-3 text-sm text-gray-400"><i data-lucide="settings"></i> Einstellungen</button>
        </div>
    </aside>

    <!-- Main Chat Area -->
    <main class="flex-1 flex flex-col h-full relative z-10 pt-14 md:pt-0">
        
        <!-- Welcome Screen (Onboarding) -->
        <div id="welcome-screen" class="absolute inset-0 flex flex-col items-center justify-center p-6 text-center z-30 bg-background/50 backdrop-blur-md">
            <div class="w-20 h-20 bg-gradient-to-tr from-blue-500/10 to-purple-500/10 rounded-2xl flex items-center justify-center border border-white/10 mb-6 shadow-2xl shadow-blue-900/20">
                <i data-lucide="cpu" class="w-10 h-10 text-white/80"></i>
            </div>
            <h1 class="text-3xl md:text-4xl font-semibold text-white mb-3 tracking-tight">Private AI. Local.</h1>
            <p class="text-gray-400 max-w-md mb-8 text-sm md:text-base leading-relaxed">
                Das Modell läuft vollständig in deinem Browser via WebGPU.<br>
                Keine Cloud, keine Kosten, deine Daten.
            </p>
            
            <button id="init-btn" class="group relative px-8 py-3 bg-white text-black font-medium rounded-full overflow-hidden transition-all hover:scale-105 active:scale-95 shadow-[0_0_40px_-10px_rgba(255,255,255,0.3)]">
                <span class="relative z-10 flex items-center gap-2">
                    Modell laden (~1GB)
                    <i data-lucide="arrow-right" class="w-4 h-4"></i>
                </span>
            </button>
        </div>

        <!-- Download Overlay -->
        <div id="download-overlay" class="hidden absolute inset-0 z-40 bg-black/80 backdrop-blur-md flex flex-col items-center justify-center p-8">
            <div class="w-full max-w-sm">
                <div class="flex justify-between text-xs font-medium text-gray-400 mb-2 uppercase tracking-wider">
                    <span id="download-status">Verbindung herstellen...</span>
                    <span id="download-percent">0%</span>
                </div>
                <!-- Custom Progress Bar -->
                <div class="h-1 w-full bg-white/10 rounded-full overflow-hidden mb-6">
                    <div id="progress-bar-fill" class="h-full bg-blue-500 w-0 transition-all duration-150 ease-out shadow-[0_0_10px_rgba(59,130,246,0.5)]"></div>
                </div>
                
                <p class="text-center text-xs text-gray-500 leading-relaxed max-w-xs mx-auto">
                    Dies geschieht nur einmal. Das Modell wird im Cache gespeichert.<br>Bitte schließe den Tab nicht.
                </p>
            </div>
            <button id="cancel-download" class="mt-8 text-sm text-red-400 hover:text-red-300 transition opacity-60 hover:opacity-100">Abbrechen</button>
        </div>

        <!-- Chat Messages -->
        <div id="chat-messages" class="flex-1 overflow-y-auto p-4 md:p-8 space-y-6 scroll-smooth">
            <!-- Messages go here -->
            <div id="empty-state" class="hidden h-full flex flex-col items-center justify-center opacity-30 pointer-events-none">
                <i data-lucide="message-square-dashed" class="w-12 h-12 mb-4"></i>
                <p>Chat gestartet</p>
            </div>
        </div>

        <!-- Input Area -->
        <div class="p-4 md:p-6 w-full max-w-3xl mx-auto z-20">
            <div class="relative glass-panel rounded-3xl p-1.5 transition-colors focus-within:bg-white/[0.02] focus-within:border-white/10 shadow-2xl">
                <textarea 
                    id="user-input" 
                    rows="1" 
                    placeholder="Frag mich etwas..." 
                    class="w-full bg-transparent text-gray-100 px-4 py-3 focus:outline-none resize-none max-h-48 text-[15px] placeholder-gray-600 rounded-2xl"
                    style="min-height: 54px;"
                ></textarea>
                
                <div class="absolute bottom-2.5 right-2.5">
                    <button 
                        id="send-btn" 
                        class="p-2 bg-white text-black rounded-xl hover:bg-gray-200 disabled:opacity-30 disabled:cursor-not-allowed transition-all shadow-lg active:scale-95"
                    >
                        <i data-lucide="arrow-up" class="w-5 h-5"></i>
                    </button>
                </div>
            </div>
            <div class="text-center mt-2">
                 <p class="text-[10px] text-gray-600">Qwen2.5-0.5B-Instruct @ WebGPU • Errors possible.</p>
            </div>
        </div>

    </main>

    <!-- Settings Modal -->
    <dialog id="settings-dialog" class="bg-[#0c0c0c] text-white rounded-2xl border border-white/10 w-full max-w-md p-0 shadow-2xl backdrop:backdrop-blur-sm">
        <div class="p-5 border-b border-white/5 flex justify-between items-center">
            <h2 class="font-medium">Einstellungen</h2>
            <form method="dialog"><button class="text-gray-500 hover:text-white"><i data-lucide="x"></i></button></form>
        </div>
        <div class="p-5 space-y-6">
            <div class="space-y-4">
                <h3 class="text-xs font-semibold text-gray-500 uppercase tracking-wider">Daten & Speicher</h3>
                
                <div class="flex items-center justify-between p-3 rounded-xl bg-white/5 border border-white/5">
                    <div>
                        <div class="text-sm font-medium">Chat Verlauf</div>
                        <div class="text-xs text-gray-500">Alle Nachrichten lokal löschen</div>
                    </div>
                    <button id="clear-chats" class="p-2 hover:bg-white/10 rounded-lg text-gray-400 hover:text-red-400 transition">
                        <i data-lucide="trash-2" class="w-4 h-4"></i>
                    </button>
                </div>

                <div class="flex items-center justify-between p-3 rounded-xl bg-white/5 border border-white/5">
                    <div>
                        <div class="text-sm font-medium">Modell Cache</div>
                        <div class="text-xs text-gray-500">~1GB Daten freigeben</div>
                    </div>
                    <button id="clear-cache" class="p-2 hover:bg-white/10 rounded-lg text-gray-400 hover:text-red-400 transition">
                        <i data-lucide="database" class="w-4 h-4"></i>
                    </button>
                </div>
            </div>
            
            <div class="pt-2 text-center">
                 <p class="text-[10px] text-gray-600">Version 2.0.0 • Transformers.js v3</p>
            </div>
        </div>
    </dialog>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0-alpha.19';

        // Icons
        lucide.createIcons();

        // --- Config ---
        // WICHTIGE ÄNDERUNG: Nutzung des "onnx-community" Namespace für garantierte Kompatibilität mit v3
        const MODEL_ID = 'onnx-community/Qwen2.5-0.5B-Instruct'; 
        
        env.allowLocalModels = false;
        env.useBrowserCache = true;
        // Optional: Falls WebGPU Probleme macht, könnten wir wasm fallbacken, aber der User will WebGPU.
        // Wir lassen es auf default, transformers.js v3 wählt das backend basierend auf device option.

        const state = {
            chats: JSON.parse(localStorage.getItem('neoai_chats_v2') || '[]'),
            activeChatId: null,
            isGenerating: false,
            modelReady: false,
        };

        let pipe = null;

        // --- UI Refs ---
        const els = {
            welcome: document.getElementById('welcome-screen'),
            download: document.getElementById('download-overlay'),
            chatArea: document.getElementById('chat-messages'),
            input: document.getElementById('user-input'),
            sendBtn: document.getElementById('send-btn'),
            chatList: document.getElementById('chat-list'),
            mobileChatList: document.getElementById('mobile-chat-list'),
            settingsDialog: document.getElementById('settings-dialog'),
            progressBar: document.getElementById('progress-bar-fill'),
            progressPercent: document.getElementById('download-percent'),
            progressStatus: document.getElementById('download-status'),
            nav: {
                desktop: document.getElementById('sidebar'),
                mobile: document.getElementById('mobile-sidebar'),
                overlay: document.getElementById('mobile-overlay'),
            }
        };

        // --- Init ---
        async function init() {
            renderChatList();
            
            // Check if model was previously loaded (naive check via localstorage flag)
            const modelCached = localStorage.getItem('neoai_model_cached') === 'true';
            
            if (state.chats.length > 0) {
                // Restore last session
                loadChat(state.chats[0].id);
            } else {
                createNewChat(true); // silent create
            }

            if(modelCached) {
                // If cached, we can technically skip big welcome, but user might want to confirm load
                // We keep welcome screen as "Start" button essentially
                els.welcome.classList.remove('hidden');
            } else {
                els.welcome.classList.remove('hidden');
            }
        }

        // --- Model Loading ---
        document.getElementById('init-btn').addEventListener('click', async () => {
            els.welcome.classList.add('hidden');
            els.download.classList.remove('hidden');
            
            try {
                // Start Pipeline
                pipe = await pipeline('text-generation', MODEL_ID, {
                    device: 'webgpu',
                    dtype: 'q4', // Quantized for 0.5B is standard
                    progress_callback: (info) => {
                        if(info.status === 'initiate') {
                             els.progressStatus.textContent = "Initialisiere GPU...";
                        } else if (info.status === 'progress') {
                            // Calculate total progress if possible or just show current file
                            const percent = info.progress ? Math.round(info.progress) : 0;
                            els.progressBar.style.width = `${percent}%`;
                            els.progressPercent.textContent = `${percent}%`;
                            
                            if (info.file) {
                                els.progressStatus.textContent = `Lade ${info.file}...`;
                            }
                        } else if (info.status === 'done') {
                             els.progressBar.style.width = `100%`;
                        }
                    }
                });
                
                // Done
                state.modelReady = true;
                localStorage.setItem('neoai_model_cached', 'true');
                
                // Hide loader with fade
                els.download.style.opacity = '0';
                els.download.style.transition = 'opacity 0.5s ease';
                setTimeout(() => {
                    els.download.classList.add('hidden');
                }, 500);

            } catch (err) {
                console.error("Model Error:", err);
                alert(`Fehler beim Laden des Modells:\n${err.message}\n\nStelle sicher, dass dein Browser WebGPU unterstützt.`);
                location.reload();
            }
        });

        document.getElementById('cancel-download').addEventListener('click', () => location.reload());

        // --- Chat Logic ---

        function createNewChat(silent = false) {
            const newChat = {
                id: Date.now().toString(),
                title: 'Neuer Chat',
                messages: [],
                updatedAt: Date.now()
            };
            state.chats.unshift(newChat);
            saveChats();
            if(!silent) loadChat(newChat.id);
            renderChatList();
            if(window.innerWidth < 768) closeMobileNav();
        }

        function loadChat(id) {
            state.activeChatId = id;
            const chat = state.chats.find(c => c.id === id);
            
            // Clear & Render
            els.chatArea.innerHTML = '';
            
            if (chat && chat.messages.length > 0) {
                chat.messages.forEach(msg => appendMessage(msg.role, msg.content, false));
                document.getElementById('empty-state').classList.add('hidden');
            } else {
                document.getElementById('empty-state').classList.remove('hidden');
            }
            
            renderChatList();
        }

        function saveChats() {
            localStorage.setItem('neoai_chats_v2', JSON.stringify(state.chats));
            renderChatList();
        }

        function renderChatList() {
            const html = state.chats.map(chat => {
                const isActive = chat.id === state.activeChatId;
                const classes = isActive 
                    ? "bg-white/10 text-white border-white/5" 
                    : "text-gray-400 hover:bg-white/5 hover:text-gray-200 border-transparent";
                
                return `
                    <button onclick="window.loadChatById('${chat.id}')" class="w-full text-left px-3 py-2.5 rounded-lg text-sm mb-1 border ${classes} transition-all truncate group flex justify-between items-center">
                        <span class="truncate">${chat.title}</span>
                        ${isActive ? '' : '<i data-lucide="chevron-right" class="w-3 h-3 opacity-0 group-hover:opacity-50"></i>'}
                    </button>
                `;
            }).join('');
            
            els.chatList.innerHTML = html;
            els.mobileChatList.innerHTML = html;
            lucide.createIcons();
        }

        // Global exposing for onclick
        window.loadChatById = (id) => loadChat(id);

        function appendMessage(role, content, animate = false) {
            document.getElementById('empty-state').classList.add('hidden');
            
            const div = document.createElement('div');
            div.className = `flex w-full ${role === 'user' ? 'justify-end' : 'justify-start'} animate-[fadeIn_0.3s_ease-out]`;
            
            // Styling based on Pathly/Clean look
            // User: Minimal rounded block, off-black/grey
            // AI: Transparent, Markdown
            
            const bubble = document.createElement('div');
            
            if (role === 'user') {
                bubble.className = "max-w-[85%] md:max-w-[70%] bg-[#1a1a1a] text-gray-100 px-5 py-3 rounded-2xl border border-white/5 shadow-sm text-[15px] leading-relaxed";
                bubble.textContent = content; 
            } else {
                bubble.className = "max-w-[90%] md:max-w-[85%] px-2 py-2 text-gray-300 prose prose-invert prose-headings:text-gray-100 prose-p:text-gray-300 prose-strong:text-white text-[15px]"; // No background for AI mostly
                bubble.innerHTML = DOMPurify.sanitize(marked.parse(content));
            }
            
            if (animate) bubble.classList.add('cursor-blink');

            div.appendChild(bubble);
            els.chatArea.appendChild(div);
            
            // Scroll logic
            requestAnimationFrame(() => {
                els.chatArea.scrollTop = els.chatArea.scrollHeight;
            });

            return bubble;
        }

        // --- Generation ---

        async function handleSend() {
            const text = els.input.value.trim();
            if (!text || state.isGenerating) return;

            if(!state.modelReady) {
                 // Try auto-init if user bypassed onboarding somehow
                 // But ideally button is disabled.
                 alert("Bitte lade erst das Modell (Button im Startscreen).");
                 return;
            }

            // UI Reset
            els.input.value = '';
            els.input.style.height = '54px';
            
            // Update State
            const chat = state.chats.find(c => c.id === state.activeChatId);
            if(!chat) return; // Should not happen
            
            chat.messages.push({ role: 'user', content: text, timestamp: Date.now() });
            
            // Auto Title
            if(chat.messages.length === 1) {
                chat.title = text.slice(0, 30);
                saveChats();
            }

            appendMessage('user', text);
            
            // Prepare Generation
            state.isGenerating = true;
            els.sendBtn.disabled = true;
            
            const aiBubble = appendMessage('assistant', '', true);
            let fullResponse = "";

            try {
                // Construct Chat Prompt (Qwen format)
                const messages = [
                    { role: 'system', content: 'Du bist NeoAI, ein intelligenter Assistent. Antworte präzise auf Deutsch.' },
                    ...chat.messages
                    // Note: Transformers.js v3 apply_chat_template feature is WIP in JS.
                    // We construct prompt manually for Qwen which is usually ChatML
                ];
                
                // Manual ChatML construction
                const prompt = messages.map(m => `<|im_start|>${m.role}\n${m.content}<|im_end|>\n`).join('') + "<|im_start|>assistant\n";
                
                // Generate
                const output = await pipe(prompt, {
                    max_new_tokens: 512,
                    temperature: 0.7,
                    do_sample: true,
                    // Note: Real streaming in v3 JS is tricky. We'll simulate typing effect if batch returns, 
                    // or use the streamer if supported.
                    // Let's rely on standard await for stability as requested "löse alle probleme".
                });

                const raw = output[0].generated_text;
                // Extract new part
                let response = raw.substring(prompt.length);
                response = response.replace('<|im_end|>', '');
                
                fullResponse = response;
                aiBubble.innerHTML = DOMPurify.sanitize(marked.parse(fullResponse));
                
                // Save
                chat.messages.push({ role: 'assistant', content: fullResponse, timestamp: Date.now() });
                saveChats();

            } catch (err) {
                aiBubble.innerHTML = `<span class="text-red-400 text-sm">Fehler: ${err.message}</span>`;
            } finally {
                aiBubble.classList.remove('cursor-blink');
                state.isGenerating = false;
                els.sendBtn.disabled = false;
                els.input.focus();
            }
        }

        // --- Event Listeners ---
        els.sendBtn.addEventListener('click', handleSend);
        els.input.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSend();
            }
            e.target.style.height = 'auto';
            e.target.style.height = Math.min(e.target.scrollHeight, 200) + 'px';
        });

        document.getElementById('new-chat-btn').addEventListener('click', () => createNewChat());
        document.getElementById('mobile-new-chat').addEventListener('click', () => createNewChat());

        // Mobile Nav
        const openMobileNav = () => {
            els.nav.mobile.classList.remove('-translate-x-full');
            els.nav.overlay.classList.remove('hidden');
            setTimeout(() => els.nav.overlay.classList.remove('opacity-0'), 10);
        };
        const closeMobileNav = () => {
            els.nav.mobile.classList.add('-translate-x-full');
            els.nav.overlay.classList.add('opacity-0');
            setTimeout(() => els.nav.overlay.classList.add('hidden'), 300);
        };
        
        document.getElementById('mobile-menu-btn').addEventListener('click', openMobileNav);
        document.getElementById('close-mobile-nav').addEventListener('click', closeMobileNav);
        els.nav.overlay.addEventListener('click', closeMobileNav);

        // Settings
        document.getElementById('settings-trigger').addEventListener('click', () => els.settingsDialog.showModal());
        document.getElementById('mobile-settings-btn').addEventListener('click', () => els.settingsDialog.showModal());

        document.getElementById('clear-chats').addEventListener('click', () => {
            if(confirm('Verlauf löschen?')) {
                state.chats = [];
                state.activeChatId = null;
                saveChats();
                createNewChat();
                els.settingsDialog.close();
            }
        });

        document.getElementById('clear-cache').addEventListener('click', async () => {
            if(confirm('Den lokalen Modell-Cache löschen? Der nächste Start dauert wieder länger.')) {
                const keys = await caches.keys();
                await Promise.all(keys.map(key => caches.delete(key)));
                localStorage.removeItem('neoai_model_cached');
                location.reload();
            }
        });

        // Start
        init();

    </script>
</body>
</html>
